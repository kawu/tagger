Morpho-syntactic tagger for Polish based on Conditional Random Fields.

The tool is still in its developmnet stage.  I'm happy to receive any comments or advices on how to improve it.


ABOUT

Morpho-syntactic tagger for Polish based on Conditional Random Fields.  For now, it lacks morphological analysis phase and provides only disambiguation functionality. 
The tager has been developed with Morfeusz tagset in mind (see http://sgjp.pl/morfeusz/), but it can be used with other, similar tagsets.


COMPILATION

To compile the program, the Glasgow Haskell Compiler (GHC) is required.  The easiest way to get the compiler is to download the latest stable release of Haskell Platform (http://hackage.haskell.org/platform/).  Any other haskell library, which is not distributed with Haskell Platform and is needed to compile the tager, can be downloaded using the cabal tool (which is bundled with the Platform).  Use the following command to compile 'tager' program from within the root directory:

$ ghc -O2 --make -isrc -o tager -outputdir tmp Main

Intermediate files will be put into 'tmp' directory.  To compile with concurrency support:

$ ghc -O2 --make -isrc -o tager -outputdir tmp -rtsopts -threaded Main


USAGE

Run the compiled program with a '--help' argument to see a list of program command line options.

$ ./tager --help

You can find more information about usage in the documentation 'docs' directory.


CONFIGURATION

Configuration consists of two files:
* Tagset configuration,
* Observations schema.
Examplary configuration -- simple schema and tagset configuration consistent with NKJP -- can be found in the 'config' directory.  More about configuration can be found in the manual.


DOCUMENTATION

Manual and algorithm description can be found in the 'docs/manual.pdf' file.  It is written in polish.  In can be compiled using the following command:

$ pdflatex manual.tex

from within the 'docs' directory.


UTILITIES

Utility tools can be found in the 'utils' directory.  To use them, python version 2.7.* is required (or 2.6.* with manually installed argparse library).  The 'utils/tei2linc/tei2linc.py' script can be used to convert data from TEI NKJP format to LINC format.  Tager can be run on a flattened  (using 'utils/lincOpts/flatten.py' script) LINC data.  The dataset should be divided (using 'utils/lincOpts/break.py' script) into a number of seperate files before the tools learning algorithm can be used.  The whole process of data preparation, model training and tagging is shown in the following section.


TRAINING

To prepare LINC data from TEI NKJP corpus, use the following commands:

$ mkdir data
$ python utils/tei2linc/tei2linc.py NKJP-PodkorpusMilionowy-1.0.tgz -b > data/orig.linc

Converted dataset contains informations, which are unnecessary during the tagging or evalutaion phase.  Use the 'flatten.py' script to get rid of them:

$ python utils/lincOpts/flatten.py data/orig.linc > data/flat.linc

Then you can manually divide it to training 'train.linc' part and evaluation 'eval.linc' part.  Use the 'break.py' script to divide datasets, so they can be used to train a model:

$ python utils/lincOpts/break.py data/train.linc data/train
$ python utils/lincOpts/break.py data/eval.linc data/eval

Finally, you can train the CRF model using the provided configuration:

$ ./tager train config/tagset.cfg config/schema.cfg data/train -e data/eval -d -o data/model.crf

Or, if the tool has been compiled with concurrency support and you want to run it on multiple (lets say, four) cores:

$ ./tager train config/tagset.cfg config/schema.cfg data/train -e data/eval -d -o data/model.crf -w 4 +RTS -N4


DESAMBIGUATION


AUTHORS

This tool is written and maintained by Jakub Waszczuk, waszczuk.kuba@gmail.com.
